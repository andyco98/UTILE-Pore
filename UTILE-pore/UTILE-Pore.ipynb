{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_3D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthreeDprediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthreeDprediction_multi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpore_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\UTILE-pore\\UTILE-pore\\threeDprediction.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gaussian_filter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models_3D\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_patches\u001b[39m(volume, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m, overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[0;32m      9\u001b[0m     patches \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models_3D'"
     ]
    }
   ],
   "source": [
    "from threeDprediction import *\n",
    "from threeDprediction_multi import *\n",
    "from pore_analysis import *\n",
    "from visualization import *\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Jupyter Notebook for the utilization of UTILE-Pore\n",
    "\n",
    "With this notebook, you will be guided through the code and make it possible for you to analyze your porous materials tomographies automatically.\n",
    "\n",
    "This notebook should help you to run the automated segmentation of the volumes in your images and afterward to apply the diverse functions to extract the information of interest from your data and visualize the results.\n",
    "\n",
    "Already integrated functions are:\n",
    "\n",
    "- GDL/porous material\n",
    "- Pore size distribution analysis of the pores with PoreSpy\n",
    "- Surface roughness calculation\n",
    "- Tortuosity simulation with PoreSpy\n",
    "- Permeability estimation using Kozeny-Carman equation\n",
    "- Calculation of the solid surface ratio\n",
    "\n",
    "\n",
    "For MPL\n",
    "- Layer thickness calculation\n",
    "- MPL crack analsis (ratio, size distribution, etc.)\n",
    "- MPL heatmap for thickness variation\n",
    "- MPL intrusion measurement\n",
    "- MPL and GDL contact surface calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give a name to your project\n",
    "\n",
    "case_name = \"example1\"\n",
    "\n",
    "#First, we need to specify the folder where the tomograph slices (or tif stack) are stored\n",
    "\n",
    "image_path= \"./path/to/image.tif\"\n",
    "\n",
    "#Secondly, we need to specify where is your model stored (.hdf5)\n",
    "\n",
    "model_path = \"./path/to/model.hdf5\"\n",
    "\n",
    "# We set the path to the csv file to store all the extracted data\n",
    "\n",
    "csv_file = './functions/csv_test.csv'\n",
    "\n",
    "#It is also required to create a folder to store the predicted masks\n",
    "\n",
    "os.makedirs(f\"./{case_name}/mask_folder\", exist_ok=True)\n",
    "mask_folder = f\"./{case_name}/mask_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we start with the segmentation of the volume\n",
    "# If you just have a porous materials and need a binary segmentation, run the following lines\n",
    "\n",
    "# input_volume = io.imread('/p/project1/claimd/Andre/Aimy/Dataset/cal_fusev2/test/Toray1202.tif')\n",
    "# predicted_volume = process_and_predict(image_path, model_path)\n",
    "# io.imsave(f'./predicted_{case_name}.tif', predicted_volume.astype(np.uint8))\n",
    "\n",
    "#If you are analyzing a GDL with MPL, then you can run a multiclass semantic segmentation with the following lines:\n",
    "input_volume = io.imread('/p/project1/claimd/Andre/Aimy/Dataset/cal_fusev2/test/Toray1202.tif')\n",
    "predicted_volume = process_and_predict_multi(input_volume)\n",
    "io.imsave(f'./predicted_{case_name}.tif', predicted_volume.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets visualize the segmented volume\n",
    "predicted_volume = io.imread('/p/project1/claimd/Andre/Aimy/Dataset/cal_fusev2/test/Toray1202.tif')\n",
    "visualize_volume(predicted_volume, case_name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can directly start wiht the property extraction of the porous material or GDL\n",
    "# We start with the pore size distribution analysis\n",
    "\n",
    "porosity, results, avg_pore, sd = calculate_psd(predicted_volume, csv_file, voxel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tortuosity simulation (for non-optimized devices can take several hours)\n",
    "#tortuosity = 1.85\n",
    "tortuosity = tortuosity_simulation(predicted_volume, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having the above mentioned properties, we can estimate the permeability\n",
    "# Estimate permeability\n",
    "ssa = calculate_ssa(predicted_volume)\n",
    "permeability = estimate_permeability(porosity, csv_file, ssa, tortuosity)\n",
    "print(f'Permeability: {permeability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then surface roughness calculation of the material\n",
    "#Calculate surface roughness\n",
    "Ra, Rq = calculate_surface_roughness_from_surface(predicted_volume)\n",
    "#MPL_roughness_calculation(binary_image_3d, mpl=2)\n",
    "print(f\"Arithmetic Mean Roughness (Ra): {Ra}\")\n",
    "print(f\"Root Mean Square Roughness (Rq): {Rq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculacte solid surface ratio\n",
    "calculate_solid_surface_ratio(predicted_volume, csv_file, gdl=1, side='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can move to the functions specialized for MPL containing GDLs\n",
    "# We can caluclate the MPL and GDL thickness\n",
    "MPL_GDL_thickness(predicted_volume, csv_file, axis=0, mpl=2, gdl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MPL crack analysis\n",
    "crack_ratio, crack_count, crack_labels, crack_sizes, slice_image = MPL_crack_analysis(predicted_volume, csv_file)\n",
    "print(f\"Crack Ratio: {crack_ratio}\")\n",
    "print(f\"Crack Count: {crack_count}\")\n",
    "print(f\"Crack Sizes: {crack_sizes}\")\n",
    "plot_crack_labels(slice_image, crack_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "Ra, Rq, Ra_std_dev, Ra_CoV, avg_thickness = MPL_intrusion_roughness(predicted_volume, csv_file, mpl=2, voxel_size=5)\n",
    "print(f\"Global Roughness Ra: {Ra}, Rq: {Rq}\")\n",
    "print(f\"Standard Deviation of Local Ra: {Ra_std_dev}\")\n",
    "print(f\"Coefficient of Variation of Local Ra: {Ra_CoV}\")\n",
    "print(f\"Average Thickness: {avg_thickness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPL heatmap creation\n",
    "MPL_heatmap(predicted_volume,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fiber touching MPL voxels\n",
    "MPL_count_touching_voxels(predicted_volume, csv_file, mpl_class=1, fiber_class=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
