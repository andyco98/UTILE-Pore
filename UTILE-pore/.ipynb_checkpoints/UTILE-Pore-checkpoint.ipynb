{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threeDprediction import *\n",
    "from threeDprediction_multi import *\n",
    "from pore_analysis import *\n",
    "from visualization import *\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Jupyter Notebook for the utilization of UTILE-Pore\n",
    "\n",
    "With this notebook, you will be guided through the code and make it possible for you to analyze your porous materials tomographies automatically.\n",
    "\n",
    "This notebook should help you to run the automated segmentation of the volumes in your images and afterward to apply the diverse functions to extract the information of interest from your data and visualize the results.\n",
    "\n",
    "Already integrated functions are:\n",
    "\n",
    "- GDL/porous material\n",
    "- Pore size distribution analysis of the pores with PoreSpy\n",
    "- Surface roughness calculation\n",
    "- Tortuosity simulation with PoreSpy\n",
    "- Permeability estimation using Kozeny-Carman equation\n",
    "- Calculation of the solid surface ratio\n",
    "\n",
    "\n",
    "For MPL\n",
    "- Layer thickness calculation\n",
    "- MPL crack analsis (ratio, size distribution, etc.)\n",
    "- MPL heatmap for thickness variation\n",
    "- MPL intrusion measurement\n",
    "- MPL and GDL contact surface calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give a name to your project\n",
    "\n",
    "case_name = \"example1\"\n",
    "\n",
    "#First, we need to specify the folder where the tomograph slices (or tif stack) are stored\n",
    "\n",
    "image_path= \"C:/Users/a.colliard/Desktop/aimys_project/CT_crops/new/totake/39bb2.tif\"\n",
    "\n",
    "#Secondly, we need to specify where is your model stored\n",
    "\n",
    "model_path = \"C:/Users/a.colliard/Downloads/HRNET_HRNET_multi_fusev2_dataset_noaug_-0.6808-23.keras\"\n",
    "\n",
    "#It is also required to create a folder to store the predicted masks\n",
    "os.makedirs(f\"./{case_name}/\", exist_ok=True)\n",
    "\n",
    "# We set the path to the csv file to store all the extracted data\n",
    "csv_file = f'./{case_name}/csv_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at HRNET",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now we start with the segmentation of the volume\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# If you just have a porous materials and need a binary segmentation, run the following lines\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#If you are analyzing a GDL with MPL, then you can run a multiclass semantic segmentation with the following lines:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m input_volume \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 10\u001b[0m predicted_volume \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_and_predict_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_volume\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m io\u001b[38;5;241m.\u001b[39mimsave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/predicted_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, predicted_volume\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8))\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\UTILE-pore\\UTILE-pore\\threeDprediction_multi.py:85\u001b[0m, in \u001b[0;36mprocess_and_predict_multi\u001b[1;34m(volume, model, patch_size, overlap, sigma)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_predict_multi\u001b[39m(volume, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHRNET\u001b[39m\u001b[38;5;124m'\u001b[39m, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m, overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# Pad the volume if necessary\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     model1 \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     depth, height, width \u001b[38;5;241m=\u001b[39m volume\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     87\u001b[0m     pad_depth \u001b[38;5;241m=\u001b[39m (patch_size \u001b[38;5;241m-\u001b[39m depth \u001b[38;5;241m%\u001b[39m patch_size) \u001b[38;5;241m%\u001b[39m patch_size\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pore_test\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pore_test\\lib\\site-packages\\keras\\saving\\save.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    203\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at HRNET"
     ]
    }
   ],
   "source": [
    "# Now we start with the segmentation of the volume\n",
    "# If you just have a porous materials and need a binary segmentation, run the following lines\n",
    "\n",
    "# input_volume = io.imread('/p/project1/claimd/Andre/Aimy/Dataset/cal_fusev2/test/Toray1202.tif')\n",
    "# predicted_volume = process_and_predict(image_path, model_path)\n",
    "# io.imsave(f'./predicted_{case_name}.tif', predicted_volume.astype(np.uint8))\n",
    "\n",
    "#If you are analyzing a GDL with MPL, then you can run a multiclass semantic segmentation with the following lines:\n",
    "input_volume = io.imread(image_path)\n",
    "predicted_volume = process_and_predict_multi(input_volume, model_path)\n",
    "io.imsave(f'./{case_name}/predicted_{case_name}.tif', predicted_volume.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets visualize the segmented volume\n",
    "predicted_volume = io.imread(f'./{case_name}/predicted_{case_name}.tif')\n",
    "visualize_volume(predicted_volume, case_name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can directly start wiht the property extraction of the porous material or GDL\n",
    "# We start with the pore size distribution analysis\n",
    "porosity, results, avg_pore, sd = calculate_psd(predicted_volume, csv_file, voxel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tortuosity simulation (for non-optimized devices can take several hours)\n",
    "#tortuosity = 1.85\n",
    "tortuosity = tortuosity_simulation(predicted_volume, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having the above mentioned properties, we can estimate the permeability\n",
    "# Estimate permeability\n",
    "ssa = calculate_ssa(predicted_volume)\n",
    "permeability = estimate_permeability(porosity, csv_file, ssa, tortuosity)\n",
    "print(f'Permeability: {permeability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then surface roughness calculation of the material\n",
    "#Calculate surface roughness\n",
    "Ra, Rq = calculate_surface_roughness_from_surface(predicted_volume)\n",
    "#MPL_roughness_calculation(binary_image_3d, mpl=2)\n",
    "print(f\"Arithmetic Mean Roughness (Ra): {Ra}\")\n",
    "print(f\"Root Mean Square Roughness (Rq): {Rq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculacte solid surface ratio\n",
    "calculate_solid_surface_ratio(predicted_volume, csv_file, gdl=1, side='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can move to the functions specialized for MPL containing GDLs\n",
    "# We can caluclate the MPL and GDL thickness\n",
    "MPL_GDL_thickness(predicted_volume, csv_file, axis=0, mpl=2, gdl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MPL crack analysis\n",
    "crack_ratio, crack_count, crack_labels, crack_sizes, slice_image = MPL_crack_analysis(predicted_volume, csv_file)\n",
    "print(f\"Crack Ratio: {crack_ratio}\")\n",
    "print(f\"Crack Count: {crack_count}\")\n",
    "print(f\"Crack Sizes: {crack_sizes}\")\n",
    "plot_crack_labels(slice_image, crack_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "Ra, Rq, Ra_std_dev, Ra_CoV, avg_thickness = MPL_intrusion_roughness(predicted_volume, csv_file, mpl=2, voxel_size=5)\n",
    "print(f\"Global Roughness Ra: {Ra}, Rq: {Rq}\")\n",
    "print(f\"Standard Deviation of Local Ra: {Ra_std_dev}\")\n",
    "print(f\"Coefficient of Variation of Local Ra: {Ra_CoV}\")\n",
    "print(f\"Average Thickness: {avg_thickness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPL heatmap creation\n",
    "MPL_heatmap(predicted_volume,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fiber touching MPL voxels\n",
    "MPL_count_touching_voxels(predicted_volume, csv_file, mpl_class=1, fiber_class=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
